{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99bf4d1922fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#File input output\n",
    "import os\n",
    "#matrix math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "#data preprocessing \n",
    "import pandas as pd\n",
    "#deep learning\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from kt_utils import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 2000\n",
    "im_height = 1\n",
    "im_chan = 3 # Number of channels: first is original and second cumsum(axis=0)\n",
    "#n_features = 1 # Number of extra features\n",
    "#path_train = '../input/train/'\n",
    "#path_test = '../input/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "def WiggleNet(input_shape)\n",
    "\n",
    "input_img = Input(shape = input_shape, name='img')\n",
    "#input_features = Input((n_features, ), name='feat')\n",
    "\n",
    "c1 = Conv2D(16, (1, 128), activation='relu', padding='same') (input_img)\n",
    "c1 = Conv2D(16, (1, 128), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((1, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (1, 64), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(32, (1, 64), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((1, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (1, 32), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(64, (1, 32), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((1, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (1, 16), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(128, (1, 16), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(1, 2)) (c4)\n",
    "\n",
    "## Join features information in the depthest layer\n",
    "#f_repeat = RepeatVector(8*8)(input_features)\n",
    "#f_conv = Reshape((8, 8, n_features))(f_repeat)\n",
    "#p4_feat = concatenate([p4, f_conv], -1)\n",
    "\n",
    "c5 = Conv2D(256, (1, 16), activation='relu', padding='same') (p4_feat)\n",
    "c5 = Conv2D(256, (1, 16), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (1, 2), strides=(1, 2), padding='same') (c5)\n",
    "#check out this skip connection thooooo\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (1, 16), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(128, (1, 16), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (1, 2), strides=(1, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (1, 32), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(64, (1, 32), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (1, 2), strides=(1, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (1, 64), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(32, (1, 64), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (1, 2), strides=(1, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (1, 128), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(16, (1, 128), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(10, (1, 1), activation='softmax') (c9)\n",
    "\n",
    "model = Model(inputs=[input_img], outputs=[outputs])\n",
    "\n",
    "return model\n",
    "#wiggle_net.compile(optimizer='adam', loss='categorical_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\n",
    "#wiggle_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiggle_net = WiggleNet(input_shape = (2000, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiggle_net.complie(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiggle_net.fit(x = X_train, y = Y_train, epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = wiggle_net.evaluate(x = X_test, y = Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(cls_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(\"({0}) {1}\".format(i, class_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
